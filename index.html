<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>VMix: Improving Text-to-Image Diffusion Model with
  Cross-Attention Mixing Control</title>

<!-- Common stylesheet -->
<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet">
<link href="static/css/bulma.min.css" rel="stylesheet">
<link rel="stylesheet" href="static/css/bulma-carousel.min.css">
<link rel="stylesheet" href="static/css/bulma-slider.min.css">
<link href="static/css/fontawesome.all.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

<!-- Vendor Stylesheets -->
<!--=================js==========================-->
<link rel="stylesheet" href="static/css/tab_gallery.css">
<link rel="stylesheet" href="static/css/juxtapose.css">
<link rel="stylesheet" href="static/css/image_card_fader.css">
<link rel="stylesheet" href="static/css/image_card_slider.css">


<link href="static/css/style.css" rel="stylesheet">

</head>

<body>
<div class="column has-text-centered">
  <h1 class="title is-1 publication-title"><span style="color:#f77605; font-weight: bold; font-style: italic; font-family: 'Arial', sans-serif; background: linear-gradient(to right, #f77605, #dd500e); -webkit-background-clip: text; color: transparent;"><strong>VMix</strong></span> <span style="color:#0a0601; font-weight: bold; font-family: Arial; letter-spacing: 0.5px;"><strong>: Improving Text-to-Image Diffusion Model with <br>Cross-Attention Mixing Control</strong></span></h1>
  <!-- <h1>VMix: Improving Text-to-Image Diffusion Model with <br>Cross-Attention Mixing Control</h1> -->
  <p id="authors"> <span style="color:#137cf3; font-family: Gill Sans">Shaojin Wu,</span><sup>1</sup></a>  <span style="color:#137cf3; font-family: Gill Sans">Fei Ding, </span><sup>1,*</sup></a> 
    <span style="color:#137cf3; font-family: Gill Sans">Mengqi Huang,</span><sup>1,2</sup></a>  <span style="color:#137cf3; font-family: Gill Sans">Wei Liu,</span><sup>1</sup> </a>  
    <span style="color:#137cf3; font-family: Gill Sans">Qian He</span><sup>1</sup></a><br> 

  <span style="font-size: 16px"><sup>1</sup> ByteDance Inc. &nbsp;&nbsp;<sup>2</sup> University of Science and Technology of China</span></p>

  <div class="column has-text-centered">
    <div class="publication-links">
      <!-- PDF Link. -->
      <span class="link-block">
        <a href=""
           class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 578 578" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
          </span>
          <span>Paper</span>
        </a>
      </span>
      <span class="link-block">
        <a href=""
           class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
              <i class="ai ai-arxiv"></i>
          </span>
          <span>arXiv</span>
        </a>
      </span>
      <!-- Code Link. -->
      <span class="link-block">
        <a href="https://github.com/fenfenfenfan/VMix"
           class="external-link button is-normal is-rounded is-dark">
          <span class="icon">
            <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
          </span>
          <span>Code</span>
          </a>
      </span>
    </div>
  </div>
</div>

<!--=================Teasers==========================-->
<section class="hero is-small">
  <div class="hero-body" style="background: #f3fafa;width: 100%">
    <!-- <div class="content"> -->
    <div class="mainshowcase">
      <!-- The expanding image container -->
      <!-- <h2 class="title is-3">Text to Image</h2> -->
      <div class="tab_container">
        <!-- Close the image -->
        <span onclick="this.parentElement.style.display='none'" class="closebtn">&times;</span>

        <!-- Expanded image -->
        <div id="juxtapose-embed" data-startingposition="30%" data-animate="true" class="juxtapose" style="height: 650px; width: 650px;">  </div>

        <div>
          <div id="juxtapose-hidden"></div>
        </div>

        <!-- Image text -->
        <div id="imgtext"></div>
      </div>

      <!-- The grid: four columns -->
      <div class="tab_row"> <!--restrict images-->
        <div class="tab_column">
          <img src="static/vmix_files/teaser/0.gif" onclick="tab_gallery_click('0');">
        </div>
        <div class="tab_column">
          <img src="static/vmix_files/teaser/11.gif" onclick="tab_gallery_click('11');">
        </div>        
        <div class="tab_column">
          <img src="static/vmix_files/teaser/10.gif" onclick="tab_gallery_click('10');">
        </div>        
        <div class="tab_column">
          <img src="static/vmix_files/teaser/9.gif" onclick="tab_gallery_click('9');">
        </div>        
        <div class="tab_column">
          <img src="static/vmix_files/teaser/5.gif" onclick="tab_gallery_click('5');">
        </div>        
        <div class="tab_column">
          <img src="static/vmix_files/teaser/3.gif" onclick="tab_gallery_click('3');">
        </div>        
        <div class="tab_column">
          <img src="static/vmix_files/teaser/6.gif" onclick="tab_gallery_click('6');">
        </div>        
        <div class="tab_column">
          <img src="static/vmix_files/teaser/7.gif" onclick="tab_gallery_click('7');">
        </div>
        <div class="tab_column">
          <img src="static/vmix_files/teaser/8.gif" onclick="tab_gallery_click('8');">
        </div>
        <div class="tab_column">
          <img src="static/vmix_files/teaser/4.gif" onclick="tab_gallery_click('4');">
        </div>
        <div class="tab_column"> 
          <img src="static/vmix_files/teaser/1.gif" onclick="tab_gallery_click('1');">
        </div>
        <div class="tab_column">
          <img src="static/vmix_files/teaser/2.gif" onclick="tab_gallery_click('2');">
        </div>


    </div>
    <div class="teaser_text">
      <p>We introduce <b>VMix</b>, which offers improved aesthetic guidance to the model via a novel condition control method called 
        value-mixed cross-attention. VMix serves as an innovative plug-and-play adapter, designed to systematically enhance aesthetic quality.</p>
      </div>
  </div>
<!-- </div> -->

</section>

<div class="content_one">
  <!-- <div class="hero-body" style="background: #f7fbfb;width: 100%"></div> -->
  <h2 style="text-align:center; color:#030303;"><b>Abstract</b></h2>
  <p>While diffusion models show extraordinary talents in text-to-image generation, 
    they may still fail to generate highly aesthetic images. More specifically, 
    there is still a gap between the generated images and the real-world aesthetic images 
    in finer-grained dimensions including color, lighting, composition, etc. 
    In this paper, we propose Cross-Attention <b>V</b>alue <b>Mix</b>ing Control (<b>VMix</b>) Adapter, 
    a plug-and-play aesthetics adapter, to upgrade the quality of generated images 
    while maintaining generality across visual concepts by 
    (1) disentangling the input text prompt into the content description and aesthetic 
    description by the initialization of aesthetic embedding, and 
    (2) integrating aesthetic conditions into the denoising process through 
    value-mixed cross-attention, with the network connected by zero-initialized linear layers. 
    Our key insight is to enhance the aesthetic presentation of existing diffusion models 
    by designing a superior condition control method, all while preserving 
    the image-text alignment. Through our meticulous design, VMix is flexible 
    enough to be applied to community models for better visual performance without retraining. 
    To validate the effectiveness of our method, we conducted extensive experiments, 
    showing that VMix outperforms other state-of-the-art methods and is compatible with 
    other community modules (e.g., LoRA, ControlNet, and IPAdapter) for image generation.</p>
    <br>
    <img class="summary-img" src="static/vmix_files/abstract.png" style="width:70%;">
    <p> Existing methods always fail to align fine-grained human preference for visually generated content.
      Images favored by human beings should excel across various fine-grained aesthetic dimensions simultaneously, 
      such as natural light, coherent color, and reasonable composition. 
      To address this challenge, we introduce <b>VMix</b>, a novel plug-and-play adapter designed to systematically 
      bridge the aesthetic quality gap between generated images and real-world counterparts across various aesthetic dimensions. </p>
</div>

<div class="content_two">
  <!-- <div class="hero-body" style="background: #f7fbfb;width: 100%"></div> -->
  <h2 style="text-align:center; color:#030303;"><b>How does it work?</b></h2>
  <img class="summary-img" src="static/vmix_files/method.png" style="width:90%;">
<br>
  <p><b>Illustration of VMix: </b></p>
    (a) In the initialization stage, pre-defined aesthetic labels are transformed into [CLS] tokens through CLIP, 
    thereby obtaining AesEmb, which only need to be processed once at the beginning of training. </p>
    (b) In the training stage, a project layer first maps the input aesthetic description y<sup>aes</sup>
    into an embedding f<sup>a</sup> of the same token dimension as the content text embedding f<sup>t</sup>. 
    The text embedding f<sup>t</sup> is then integrated into the denoising network through value-mixed cross-attention. </p>
    (c) In the inference stage, VMix extract all positive aesthetic embedding from AesEmb to form the aesthetic input, 
    along with the content input, is fed into the model for the denoising process.</p>
</div>

<div class="content_one">
  <h2 style="text-align:center; color:#030303;"><b>Aesthetic Fine-grained Control</b></h2>
  <p>VMix can achieve fine-grained aesthetic control by adjusting the aesthetic embedding. 
    When using only single-dimensional aesthetic labels, it can be observed that the image quality improves in specific dimensions. 
    When employing full positive aesthetic labels, the visual performance of the images is superior to the baseline overall. </p><br>
  <div class="aes-main">
    <img class="aes-img" id="aes-img" src="static/vmix_files/dimension/slider.gif">
   <div class="aes-text"> “A girl leaning against a window with a breeze blowing, <br>summer portrait, half-length medium view”
    <br><br> <span class="aes-bracket"><span class="aes-button_a">full</span> &ensp;&ensp;&ensp;&ensp;&ensp; <span class="aes-button_a">baseline</span> &ensp;&ensp;&ensp;&ensp;&ensp; </br> 
    <span class="aes-button_a">light</span> &ensp;&ensp;&ensp;&ensp; <span class="aes-button_a">emotion</span> &ensp;&ensp;&ensp;&ensp; <span class="aes-button_a">texture</span> &ensp;&ensp;&ensp;&ensp; <span class="aes-button_a">color</span> &ensp;&ensp;&ensp;&ensp; <span class="aes-button_a">none</span></span>
  </div>
  </div>  
</div>  

<div class="content_two">
  <h2 style="text-align:center; color:#030303;"><b>Comparison To Current Methods</b></h2>
  <p style="text-align:center; font-size: 20px; font-family: Google Sans">  Qualitative comparison with various state-of-the-art methods. All results are based on Stable Diffusion.</p>
  <br>
  <img class="summary-img" src="static/vmix_files/comparison/sd15.png" style="width:90%;">
  <br>
  <p style="text-align:center; font-size: 20px; font-family: Google Sans">   Qualitative comparison with various state-of-the-art methods. All the results of the methods are based on the SDXL.</p>
  <br>
  <img class="summary-img" src="static/vmix_files/comparison/sdxl.png" style="width:90%;">
  <br>
</div>  

<div class="content_one">
  <h2 style="text-align:center; color:#030303;"><b>Personalized Text-to-Image Model</b></h2>
  <p style="text-align:center; font-size: 20px; font-family: Google Sans">   Images generated by the personalized model with or without VMix.</p>
  <img class="summary-img" src="static/vmix_files/comparison/public_models.png" style="width:85%;">
  <br>
</div>
<!-- </div> -->


<div class="content_two">
  <br>
  <h3>BibTex</h3>
  <p> @article{,<br>
  &nbsp;&nbsp;title={VMix: Improving Text-to-Image Diffusion Model with
    Cross-Attention Mixing Control},<br>
  &nbsp;&nbsp;author={},<br>
  &nbsp;&nbsp;booktitle={},<br>
  &nbsp;&nbsp;year={}<br>
  } </p>
</div>


<!-- Video display scripts -->
<script>
  var videos = document.getElementsByClassName("clickplay");
  for (var i = 0; i < videos.length; i++) {
    videos[i].addEventListener("click", function() {
      this.play();
    });
    videos[i].addEventListener("ended", function() {
      this.pause();
      this.currentTime = 0;
    });
  }
  </script>
</html>


<!-- Image Slider Javascripts -->
<!--=================Functions==========================-->
<script src="static/js/juxtapose.js"></script>

<script>
  var slider;
  let origImages = [
    { "src": "static/vmix_files/teaser/0.png", "label": "SDXL", },
    { "src": "static/vmix_files/teaser/vmix_0.png", "label": "VMix", }
  ];
  let origOptions = {
    "makeResponsive": true,
    "showLabels": true,
    "mode": "horizontal",
    "showCredits": true,
    "animate": true,
    "startingPosition": "50"
  };

  const juxtaposeSelector = "#juxtapose-embed";
  const transientSelector = "#juxtapose-hidden";

  
  function tab_gallery_click(name) {
    // Get the expanded image
    let inputImage = {
      label: "SDXL",
    };
    let outputImage = {
      label: "VMix",
    };

    inputImage.src = "static/vmix_files/teaser/".concat(name, ".png")
    outputImage.src = "static/vmix_files/teaser/".concat("vmix_", name, ".png")

    let images = [inputImage, outputImage];
    let options = slider.options;
    options.callback = function (obj) {
      var newNode = document.getElementById(obj.selector.substring(1));
      var oldNode = document.getElementById(juxtaposeSelector.substring(1));
      console.log(obj.selector.substring(1));
      console.log(newNode.children[0]);
      oldNode.replaceChild(newNode.children[0], oldNode.children[0]);
      //newNode.removeChild(newNode.children[0]);

    };
    slider = new juxtapose.JXSlider(transientSelector, images, options);
  };


  (function () {
    slider = new juxtapose.JXSlider(
      juxtaposeSelector, origImages, origOptions);
    //document.getElementById("left-button").onclick = replaceLeft;
    //document.getElementById("right-button").onclick = replaceRight;
  })();

</script>

<!-- image change script -->
<script>
var aes_dims;
var hats;
var cur_dim = 0;
var cur_hat = 0;
var image;



function changeImage(){
    image.src = "static/vmix_files/dimension/" + aes_dims[cur_dim].innerHTML.toLowerCase() + ".png"

}

function clearStyle(elem){
    elem.style.color = '#8e8e8e';
    elem.style.backgroundColor = null;
}

function setStyle(elem){
    elem.style.color = '#000000';
    elem.style.backgroundColor = '#f88000';
}

function modifyAes(i){

    function inner_(){
        if (cur_dim !== i){
            clearStyle(aes_dims[cur_dim]);
            cur_dim = i;
            setStyle(aes_dims[cur_dim]);
            changeImage();
        }
    }
    return inner_
}

function init() {
    image = document.getElementById("aes-img");
	  aes_dims = document.getElementsByClassName("aes-button_a");
    setStyle(aes_dims[cur_dim]);
    for (let i = 0; i < aes_dims.length; ++i){
        aes_dims[i].addEventListener("click", modifyAes(i));
    }


}
document.addEventListener("DOMContentLoaded", () => {
  init();
});
</script>

</body>
</html>